# LangGraph Ã— PostgreSQL ì™„ì „ ê°€ì´ë“œ

> **ì°¸ì¡°:**  
> â€¢ LangGraph Persistence Docs â€“ Checkpointer Libraries: <https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries>  
> â€¢ `langgraph-checkpoint-postgres` PyPI: <https://pypi.org/project/langgraph-checkpoint-postgres/>  
> â€¢ pgvector ê³µì‹ ë¬¸ì„œ: <https://github.com/pgvector/pgvector>

LangGraphëŠ” CheckpointerÂ·StoreÂ·Streaming ê°™ì€ í•µì‹¬ ê¸°ëŠ¥ì„ **DB-ë…ë¦½ì  ì¸í„°í˜ì´ìŠ¤**ë¡œ ì¶”ìƒí™”í•©ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” **PostgreSQL**ì„ í™œìš©í•˜ì—¬

1. **Checkpoint**(ê·¸ë˜í”„ ìƒíƒœ) ì˜êµ¬ ì €ì¥  
2. **ìŠ¤íŠ¸ë¦¬ë°** ì‘ë‹µ ì œê³µ  
3. **Vector DB** + ì‹œë©˜í‹± ê²€ìƒ‰

ì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

---

## 1. ì™œ PostgreSQLì¸ê°€?

| í•­ëª© | ì¥ì  | ë¹„ê³  |
|------|------|------|
| ì‹ ë¢°ì„± | ACID íŠ¸ëœì­ì…˜, WAL ë³µêµ¬ | ìš´ì˜ ê²½í—˜ í’ë¶€ |
| í™•ì¥ì„± | íŒŒí‹°ì…”ë‹Â·ë¦¬í”Œë¦¬ì¹´Â·í´ëŸ¬ìŠ¤í„°ë§ | ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ RDS, CloudSQL ë“± |
| JSON ì§€ì› | `JSONB` ì»¬ëŸ¼ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° ì €ì¥ | ğŸš€ |
| ë²¡í„° ê²€ìƒ‰ | `pgvector` í™•ì¥ìœ¼ë¡œ ë‚´ì¥ ë²¡í„° ì¸ë±ì‹± | Top-K Cosine/L2/Inner |

---

## 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install langgraph-checkpoint-postgres psycopg2-binary pgvector
```

> `pgvector` íŒŒì´ì¬ íŒ¨í‚¤ì§€ëŠ” ì„ íƒì ì´ì§€ë§Œ, ì˜ˆì œì—ì„œ í¸ì˜ìƒ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## 3. Checkpointë¥¼ PostgreSQLì— ì €ì¥í•˜ê¸°

### 3-1. ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„

```sql
-- DB ì ‘ì† í›„ ë‹¨ í•œë²ˆ ì‹¤í–‰
CREATE EXTENSION IF NOT EXISTS pgcrypto; -- UUID ìƒì„±ìš© (ì„ íƒ)
```

LangGraphëŠ” ìì²´ì ìœ¼ë¡œ í…Œì´ë¸”/ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ë¯€ë¡œ ë³„ë„ ìŠ¤í‚¤ë§ˆ ì¤€ë¹„ê°€ ì—†ìŠµë‹ˆë‹¤.

### 3-2. ì½”ë“œ ì˜ˆì‹œ

```python
from langgraph.graph import StateGraph
from langgraph.checkpoint.postgres import PostgresSaver
import os

PG_URL = os.getenv("POSTGRES_URL", "postgresql://user:pass@localhost:5432/db")

checkpointer = PostgresSaver.from_conn_string(PG_URL)
checkpointer.setup()  # âš ï¸ ìµœì´ˆ 1íšŒ ì¸ë±ìŠ¤ ìƒì„±

builder = StateGraph(int)
builder.add_node("add_one", lambda x: x + 1)
builder.set_entry_point("add_one")

graph = builder.compile(checkpointer=checkpointer)

config = {"configurable": {"thread_id": "thread-1"}}
print(graph.invoke(1, config))  # 2
```

### 3-3. TTLÂ·ì•”í˜¸í™”Â·ë¹„ë™ê¸°

| ê¸°ëŠ¥ | ë°©ë²• |
|------|------|
| **TTL** | `PostgresSaver(ttl={"default_ttl": 1440})` (ë¶„ ë‹¨ìœ„) |
| **AES ì•”í˜¸í™”** | `serde=EncryptedSerializer.from_pycryptodome_aes()` ì „ë‹¬ |
| **Async** | `AsyncPostgresSaver` ì‚¬ìš© + `await graph.ainvoke()` |

---

## 4. FastAPI ìŠ¤íŠ¸ë¦¬ë°ê³¼ PostgreSQL

PostgreSQLì€ **ìŠ¤íŠ¸ë¦¬ë° ë¡œì§ê³¼ ì™„ì „íˆ ë¶„ë¦¬**ë©ë‹ˆë‹¤. LLM í† í°ì´ ìƒì„±ë˜ëŠ” ì¦‰ì‹œ FastAPI `StreamingResponse`ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì „ë‹¬ë˜ê³ , ì²´í¬í¬ì¸í„°ëŠ” ìŠˆí¼ìŠ¤í… ì¢…ë£Œ í›„ í•œë²ˆë§Œ DBì— ê¸°ë¡í•©ë‹ˆë‹¤.

```python
from fastapi.responses import StreamingResponse

@router.post("/chat/stream")
async def chat_stream(req: ChatRequest):
    cfg = {"configurable": {"thread_id": req.thread_id}}
    gen = graph.stream({"messages": req.to_messages()}, cfg, stream_mode="updates")
    return StreamingResponse((json.dumps(e) for e in gen), media_type="text/event-stream")
```

> ì‹¤ì‹œê°„ UXê°€ ì¤‘ìš”í•œ ê²½ìš° PostgreSQL â†’ ì• í”Œë¦¬ì¼€ì´ì…˜ â†’ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ì˜ ë²„í¼ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ `psycopg2` `autocommit` ë˜ëŠ” ì»¤ë„¥ì…˜ í’€(eg. `asyncpg`) íŠœë‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

---

## 5. PostgreSQLì„ Vector DBë¡œ í™œìš© (pgvector)

### 5-1. í™•ì¥ í™œì„±í™”

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### 5-2. í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ

```sql
CREATE TABLE semantic_docs (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  content text,
  embedding vector(768)  -- OpenAI Ada: 1536, MiniLM: 384 ë“±
);

-- HNSW ì¸ë±ìŠ¤ (Cosine)
CREATE INDEX ON semantic_docs USING hnsw (embedding vector_cosine_ops);
```

### 5-3. íŒŒì´ì¬ ì‚½ì…/ê²€ìƒ‰

```python
import openai, psycopg2, numpy as np

def embed(text: str) -> list[float]:
    return openai.Embedding.create(model="text-embedding-3-small", input=text)["data"][0]["embedding"]

with psycopg2.connect(PG_URL) as conn, conn.cursor() as cur:
    # ì‚½ì…
    cur.execute("INSERT INTO semantic_docs (content, embedding) VALUES (%s, %s)",
                ("íœ´ëŒ€ìš© ë¸”ë£¨íˆ¬ìŠ¤ ìŠ¤í”¼ì»¤", np.array(embed("íœ´ëŒ€ìš© ë¸”ë£¨íˆ¬ìŠ¤ ìŠ¤í”¼ì»¤"))))
    # ê²€ìƒ‰ (Top-K)
    cur.execute("SELECT content FROM semantic_docs ORDER BY embedding <=> %s LIMIT 5", (np.array(embed("ê°€ì„±ë¹„ ìŠ¤í”¼ì»¤")),))
    print(cur.fetchall())
```

### 5-4. LangGraph Storeë¡œ ë˜í•‘í•˜ê¸°

ì•„ì§ ê³µì‹ PostgresStore êµ¬í˜„ì€ ì—†ì§€ë§Œ, `BaseStore` í”„ë¡œí† ì½œì„ êµ¬í˜„í•´ `search/put/get` ë©”ì„œë“œì—ì„œ ìœ„ SQLì„ í˜¸ì¶œí•˜ë©´ LangGraph ë…¸ë“œì—ì„œ ë™ì¼í•œ APIë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

```python
from langgraph.store.base import BaseStore, Item
from uuid import uuid4

class PgVectorStore(BaseStore):
    def __init__(self, conn_str: str):
        self.conn_str = conn_str

    def put(self, namespace: tuple[str, ...], key: str, value: dict, **kwargs):
        # namespace â†’ í…Œì´ë¸” or ì¶”ê°€ ì»¬ëŸ¼ í™œìš©
        ...

    def search(self, namespace, query: str, limit: int = 5):
        ...  # pgvector <=> ì—°ì‚°ì ì‚¬ìš©
```

---

## 6. ìš´ì˜ íŒ

1. **ì»¤ë„¥ì…˜ í’€** â€“ `asyncpg.pool` ë˜ëŠ” SQLAlchemy `AsyncSession`ìœ¼ë¡œ  DB ì—°ê²° ìˆ˜ ì œí•œ.  
2. **ë§ˆì´ê·¸ë ˆì´ì…˜** â€“ `alembic`ìœ¼ë¡œ Checkpointer í…Œì´ë¸” ì™¸ ì‚¬ìš©ì í…Œì´ë¸”(ë¦¬í¬íŠ¸, ë²¡í„°) ìŠ¤í‚¤ë§ˆ ê´€ë¦¬.  
3. **ëª¨ë‹ˆí„°ë§** â€“ `pg_stat_activity`, `auto_explain` ë¡œ ì¥ê¸° ì‹¤í–‰ ì¿¼ë¦¬ ì¶”ì .  
4. **ë°±ì—…** â€“ WAL-G, pg_dump, ê´€ë¦¬í˜• RDS snapshot í™œìš©.

---

## 7. ìš”ì•½

| ê¸°ëŠ¥ | PostgreSQL ì ìš© ë°©ë²• | ë¹„ê³  |
|------|--------------------|------|
| **Checkpoint** | `PostgresSaver` / `AsyncPostgresSaver` | JSONB + ì¸ë±ìŠ¤ ìë™ ìƒì„± |
| **Streaming** | FastAPI `StreamingResponse` & `graph.stream()` | DBì™€ ë…ë¦½ì , ì‹¤ì‹œê°„ í† í° ì „ì†¡ |
| **Semantic Search** | `pgvector` í™•ì¥ + HNSW ì¸ë±ìŠ¤ | Store ë˜í¼ êµ¬í˜„ ê°€ëŠ¥ |

PostgreSQL í•˜ë‚˜ë¡œ **ì˜ì†ì„±Â·ê²€ìƒ‰Â·í™•ì¥ì„±**ì„ ëª¨ë‘ ì¶©ì¡±ì‹œí‚¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë³„ë„ Redis ì—†ì´ë„ ì„œë¹„ìŠ¤ ìš´ì˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
