import os
from typing import TypedDict, List, Annotated, Optional
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END, add_messages
from langgraph.types import Send
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from google.genai import Client
import operator

# Environment setup
from dotenv import load_dotenv
load_dotenv()

# Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
genai_client = Client(api_key=os.getenv("GEMINI_API_KEY"))

# ========== ìƒíƒœ ì •ì˜ ==========

class Product(TypedDict):
    name: str
    source_url: str
    purchase_link: str
    review_summary: str
    price_range: str

class ProductRecommendationState(TypedDict):
    # ëŒ€í™” ê¸°ë¡ (LangGraph í‘œì¤€)
    messages: Annotated[list, add_messages]
    
    # ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ê²°ê³¼
    is_request_specific: bool
    user_intent: str
    
    # ê²€ìƒ‰ ê´€ë ¨ ë°ì´í„°
    search_queries: Annotated[list, operator.add]
    search_results: Annotated[list, operator.add]
    
    # ì œí’ˆ ë°ì´í„°
    candidate_products: Annotated[list, operator.add]
    sources_gathered: Annotated[list, operator.add]  # ì¶œì²˜ ì¶”ì 
    
    # reflection ê´€ë ¨ ìƒíƒœ
    is_sufficient: bool
    additional_queries: Annotated[list, operator.add]
    search_loop_count: int
    max_search_loops: int
    
    # ì‘ë‹µ ë°ì´í„°
    response_to_user: str
    
    # ì„¤ì •ê°’
    max_products: int
    search_depth: int

class RequestValidationState(BaseModel):
    is_specific: bool = Field(description="ìš”ì²­ì´ êµ¬ì²´ì ì¸ì§€ ì—¬ë¶€")
    clarification_question: str = Field(description="êµ¬ì²´í™”ë¥¼ ìœ„í•œ ì§ˆë¬¸")
    extracted_requirements: dict = Field(description="ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­")

class SearchQueryState(BaseModel):
    queries: List[str] = Field(description="ìƒì„±ëœ ê²€ìƒ‰ì–´ ëª©ë¡")
    rationale: str = Field(description="ê²€ìƒ‰ì–´ ì„ íƒ ì´ìœ ")

class ReflectionResult(BaseModel):
    is_sufficient: bool = Field(description="í˜„ì¬ ê²°ê³¼ê°€ ì¶©ë¶„í•œì§€ ì—¬ë¶€")
    additional_queries: List[str] = Field(description="ì¶”ê°€ ê²€ìƒ‰ì–´ ëª©ë¡")
    gap_analysis: str = Field(description="ë¶€ì¡±í•œ ë¶€ë¶„ ë¶„ì„")

# ========== ì„¤ì • ì‹œìŠ¤í…œ ==========

class ProductRecommendationConfig(BaseModel):
    # LLM ëª¨ë¸ ì„¤ì •
    validation_model: str = Field(default="gemini-2.5-flash", description="ìš”ì²­ ê²€ì¦ìš© ëª¨ë¸")
    search_model: str = Field(default="gemini-2.5-flash", description="ê²€ìƒ‰ì–´ ìƒì„±ìš© ëª¨ë¸")
    analysis_model: str = Field(default="gemini-2.5-flash", description="ì œí’ˆ ë¶„ì„ìš© ëª¨ë¸")
    
    # ê²€ìƒ‰ ì„¤ì •
    max_search_queries: int = Field(default=3, description="ìµœëŒ€ ê²€ìƒ‰ì–´ ìˆ˜")
    max_products_per_query: int = Field(default=5, description="ê²€ìƒ‰ì–´ë‹¹ ìµœëŒ€ ì œí’ˆ ìˆ˜")
    max_candidate_products: int = Field(default=10, description="ìµœëŒ€ í›„ë³´ ì œí’ˆ ìˆ˜")
    
    @classmethod
    def from_runnable_config(cls, config: Optional[RunnableConfig] = None) -> "ProductRecommendationConfig":
        """Create a Configuration instance from a RunnableConfig."""
        configurable = (
            config["configurable"] if config and "configurable" in config else {}
        )
        
        # Get raw values from environment or config
        raw_values = {
            name: os.environ.get(name.upper(), configurable.get(name))
            for name in cls.model_fields.keys()
        }
        
        # Filter out None values
        values = {k: v for k, v in raw_values.items() if v is not None}
        
        return cls(**values)

# ========== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ==========

def get_latest_user_message(messages: List) -> str:
    """ìµœì‹  ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ"""
    for message in reversed(messages):
        if hasattr(message, 'type') and message.type == 'human':
            return message.content
        elif isinstance(message, dict) and message.get('type') == 'human':
            return message['content']
    return ""

# ========== ë…¸ë“œ êµ¬í˜„ ==========

def validate_request(state: ProductRecommendationState, config: RunnableConfig) -> dict:
    """ì‚¬ìš©ì ìš”ì²­ì˜ êµ¬ì²´ì„±ì„ ê²€ì¦í•˜ê³  í•„ìš”ì‹œ êµ¬ì²´í™” ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    configurable = ProductRecommendationConfig.from_runnable_config(config)
    
    # LLM ì´ˆê¸°í™”
    llm = ChatGoogleGenerativeAI(
        model=configurable.validation_model,
        temperature=0.1,
        max_retries=2,
        api_key=os.getenv("GEMINI_API_KEY")
    )
    
    # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ ì ìš©
    structured_llm = llm.with_structured_output(RequestValidationState)
    
    # ì‚¬ìš©ì ìš”ì²­ ì¶”ì¶œ
    user_message = get_latest_user_message(state["messages"])
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    validation_prompt = get_validation_prompt(user_message)
    
    # LLM í˜¸ì¶œ
    result = structured_llm.invoke(validation_prompt)
    
    return {
        "is_request_specific": result.is_specific,
        "response_to_user": result.clarification_question if not result.is_specific else "",
        "user_intent": result.extracted_requirements.get("intent", "")
    }

def get_validation_prompt(user_message: str) -> List:
    """ìš”ì²­ ê²€ì¦ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    system_prompt = """ë‹¹ì‹ ì€ ì œí’ˆ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì œí’ˆ ê²€ìƒ‰ì— ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

êµ¬ì²´ì ì¸ ìš”ì²­ì˜ ê¸°ì¤€:
- ì œí’ˆ ì¹´í…Œê³ ë¦¬ê°€ ëª…í™•í•¨ (ì˜ˆ: ë…¸íŠ¸ë¶, ì´ì–´í°, í‚¤ë³´ë“œ ë“±)
- ìš©ë„ë‚˜ ëª©ì ì´ ì–¸ê¸‰ë¨ (ì˜ˆ: ê²Œì´ë°ìš©, ì—…ë¬´ìš©, í•™ìŠµìš© ë“±)
- ì˜ˆì‚°ì´ë‚˜ ê°€ê²©ëŒ€ê°€ ì–¸ê¸‰ë¨ (ì˜ˆ: 10ë§Œì› ì´í•˜, ê°€ì„±ë¹„ ë“±)
- ë¸Œëœë“œ ì„ í˜¸ë„ë‚˜ íŠ¹ì • ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ì´ ìˆìŒ

ë¶ˆì¶©ë¶„í•œ ìš”ì²­ ì˜ˆì‹œ:
- "í‚¤ë³´ë“œ ì¶”ì²œí•´ì¤˜"
- "ì¢‹ì€ ë…¸íŠ¸ë¶ ì•Œë ¤ì¤˜"
- "ì´ì–´í° ë­ê°€ ì¢‹ì„ê¹Œ?"

ì¶©ë¶„í•œ ìš”ì²­ ì˜ˆì‹œ:
- "10ë§Œì› ì´í•˜ ê°€ì„±ë¹„ ì¢‹ì€ ê²Œì´ë° í‚¤ë³´ë“œ ì¶”ì²œí•´ì¤˜"
- "ëŒ€í•™ìƒìš© ë¬¸ì„œì‘ì—… ë…¸íŠ¸ë¶ ì¶”ì²œ, ì˜ˆì‚° 100ë§Œì›"
- "ìš´ë™í•  ë•Œ ì“¸ ë¬´ì„  ì´ì–´í°, ë°©ìˆ˜ ê¸°ëŠ¥ ìˆëŠ” ê±¸ë¡œ"

ì‘ë‹µ í˜•ì‹:
- is_specific: true/false
- clarification_question: ë¶ˆì¶©ë¶„í•  ê²½ìš° êµ¬ì²´í™”ë¥¼ ìœ„í•œ ì§ˆë¬¸ (í•œêµ­ì–´)
- extracted_requirements: ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­ë“¤"""

    return [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì‚¬ìš©ì ìš”ì²­: {user_message}")
    ]

def generate_search_queries(state: ProductRecommendationState, config: RunnableConfig) -> dict:
    """êµ¬ì²´í™”ëœ ìš”ì²­ì„ ë°”íƒ•ìœ¼ë¡œ íš¨ê³¼ì ì¸ ê²€ìƒ‰ì–´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    configurable = ProductRecommendationConfig.from_runnable_config(config)
    
    llm = ChatGoogleGenerativeAI(
        model=configurable.search_model,
        temperature=0.7,
        max_retries=2,
        api_key=os.getenv("GEMINI_API_KEY")
    )
    
    structured_llm = llm.with_structured_output(SearchQueryState)
    
    user_intent = state.get("user_intent", "")
    user_message = get_latest_user_message(state["messages"])
    
    search_prompt = get_search_query_prompt(user_message, user_intent, configurable.max_search_queries)
    result = structured_llm.invoke(search_prompt)
    
    return {"search_queries": result.queries}

def continue_to_web_search(state: ProductRecommendationState):
    """LangGraphì˜ Send ì´ë²¤íŠ¸ë¥¼ ì‚¬ìš©í•œ ë™ì  ë³‘ë ¬ ê²€ìƒ‰"""
    return [
        Send("web_search", {"search_query": query, "id": int(idx)})
        for idx, query in enumerate(state["search_queries"])
    ]

def get_search_query_prompt(user_message: str, user_intent: str, max_queries: int) -> List:
    """ê²€ìƒ‰ì–´ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸"""
    system_prompt = f"""ë‹¹ì‹ ì€ ì œí’ˆ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ íš¨ê³¼ì ì¸ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ê²€ìƒ‰ì–´ ìƒì„± ì›ì¹™:
1. í•œêµ­ ì»¤ë®¤ë‹ˆí‹°ì™€ ë¦¬ë·° ì‚¬ì´íŠ¸ì—ì„œ ì˜ ê²€ìƒ‰ë  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œ ì‚¬ìš©
2. ê° ê²€ìƒ‰ì–´ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì„ ë‹¤ë¤„ì•¼ í•¨
3. ìµœëŒ€ {max_queries}ê°œê¹Œì§€ ìƒì„±
4. ë¸Œëœë“œëª…, ê°€ê²©ëŒ€, ìš©ë„, ì„±ëŠ¥ ë“± ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ì ‘ê·¼

ê²€ìƒ‰ì–´ ì˜ˆì‹œ:
- "ê°€ì„±ë¹„ ê²Œì´ë° í‚¤ë³´ë“œ ì¶”ì²œ 2024 ë””ì‹œ"
- "10ë§Œì› ì´í•˜ ê¸°ê³„ì‹ í‚¤ë³´ë“œ í›„ê¸° í´ë¦¬ì•™"
- "ë¡œì§€í… ë ˆì´ì € í‚¤ë³´ë“œ ë¦¬ë·° ì‚¬ìš©ê¸°"

ì‘ë‹µ í˜•ì‹:
- queries: ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸
- rationale: ê° ê²€ìƒ‰ì–´ë¥¼ ì„ íƒí•œ ì´ìœ """

    return [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì‚¬ìš©ì ìš”ì²­: {user_message}\nì¶”ì¶œëœ ì˜ë„: {user_intent}")
    ]

def web_search(state: dict, config: RunnableConfig) -> dict:
    """Gemini APIì˜ Google Search ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ì œí’ˆ í›„ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    configurable = ProductRecommendationConfig.from_runnable_config(config)
    
    # ë‹¨ì¼ ê²€ìƒ‰ì–´ ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    query = state["search_query"]
    search_id = state["id"]
    
    try:
        # Geminiì— ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        search_prompt = f"""ë‹¤ìŒ ê²€ìƒ‰ì–´ë¡œ í•œêµ­ ì œí’ˆ ì¶”ì²œ ì‚¬ì´íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”: "{query}"

ê²€ìƒ‰ ì‹œ ì£¼ëª©í•  ì‚¬ì´íŠ¸:
- ë„¤ì´ë²„ ë¸”ë¡œê·¸, ì¹´í˜
- ë””ì‹œì¸ì‚¬ì´ë“œ
- í´ë¦¬ì•™
- ë½ë¿Œ
- ë‹¤ë‚˜ì™€
- ì¿ íŒ¡, ë„¤ì´ë²„ì‡¼í•‘

ê° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
1. ì¶”ì²œ ì œí’ˆëª… (ì •í™•í•œ ëª¨ë¸ëª…)
2. ê°€ê²© ì •ë³´
3. ì£¼ìš” íŠ¹ì§• ë° ì¥ì 
4. ì¶”ì²œ ì´ìœ 
5. ì¶œì²˜ URL"""

        # Gemini API í˜¸ì¶œ (Google Search ë„êµ¬ í¬í•¨)
        response = genai_client.models.generate_content(
            model=configurable.search_model,
            contents=search_prompt,
            config={
                "tools": [{"google_search": {}}],
                "temperature": 0.3,
            }
        )
        
        # grounding metadataì—ì„œ ì¶œì²˜ ì •ë³´ ì¶”ì¶œ (quickstart ë°©ì‹)
        sources_gathered = []
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'grounding_metadata') and candidate.grounding_metadata:
                for chunk in candidate.grounding_metadata.grounding_chunks:
                    if hasattr(chunk, 'web') and chunk.web:
                        sources_gathered.append({
                            "title": chunk.web.title,
                            "url": chunk.web.uri,
                            "search_id": search_id
                        })
        
        # ì œí’ˆ ì •ë³´ ì¶”ì¶œ
        products = extract_products_from_search_result(response.text, sources_gathered)
        
        return {
            "search_queries": [query],
            "candidate_products": products,
            "sources_gathered": sources_gathered
        }
        
    except Exception as e:
        print(f"ê²€ìƒ‰ ì˜¤ë¥˜ ({query}): {e}")
        return {
            "search_queries": [query],
            "candidate_products": [],
            "sources_gathered": []
        }

def extract_products_from_search_result(content: str, sources: List) -> List[Product]:
    """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œí’ˆ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    products = []
    
    try:
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œí’ˆ ì •ë³´ ì¶”ì¶œ ë¡œì§
        if "ì¶”ì²œ" in content and ("ì œí’ˆ" in content or "ìƒí’ˆ" in content):
            # ê°„ë‹¨í•œ íŒŒì‹± - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ LLM ê¸°ë°˜ ì¶”ì¶œ í•„ìš”
            lines = content.split('\n')
            current_product = {}
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # ì œí’ˆëª… ì¶”ì¶œ ì‹œë„
                if any(keyword in line for keyword in ['ì¶”ì²œ', 'ë² ìŠ¤íŠ¸', 'ì¸ê¸°', 'ìˆœìœ„']):
                    if current_product and current_product.get('name'):
                        products.append(current_product)
                        current_product = {}
                    
                    current_product = {
                        "name": line[:50],  # ì²« 50ìë§Œ
                        "source_url": sources[0]["url"] if sources else "",
                        "purchase_link": "",
                        "review_summary": content[:200] + "...",
                        "price_range": "ê°€ê²© ì •ë³´ í™•ì¸ í•„ìš”"
                    }
            
            # ë§ˆì§€ë§‰ ì œí’ˆ ì¶”ê°€
            if current_product and current_product.get('name'):
                products.append(current_product)
            
            # ìµœì†Œ 1ê°œëŠ” ë°˜í™˜
            if not products and sources:
                products.append({
                    "name": f"ê²€ìƒ‰ ê²°ê³¼ ì œí’ˆ ({len(sources)}ê°œ ì¶œì²˜)",
                    "source_url": sources[0]["url"],
                    "purchase_link": "",
                    "review_summary": content[:200] + "..." if content else "ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                    "price_range": "ê°€ê²© ì •ë³´ í™•ì¸ í•„ìš”"
                })
                
    except Exception as e:
        print(f"ì œí’ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
    
    return products[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€

def reflection(state: ProductRecommendationState, config: RunnableConfig) -> dict:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³  ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
    
    configurable = ProductRecommendationConfig.from_runnable_config(config)
    
    llm = ChatGoogleGenerativeAI(
        model=configurable.analysis_model,
        temperature=0.1,
        max_retries=2,
        api_key=os.getenv("GEMINI_API_KEY")
    )
    
    # í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
    user_message = get_latest_user_message(state["messages"])
    candidate_products = state.get("candidate_products", [])
    search_queries = state.get("search_queries", [])
    
    reflection_prompt = get_reflection_prompt(user_message, candidate_products, search_queries)
    
    structured_llm = llm.with_structured_output(ReflectionResult)
    result = structured_llm.invoke(reflection_prompt)
    
    return {
        "is_sufficient": result.is_sufficient,
        "additional_queries": result.additional_queries if not result.is_sufficient else [],
        "search_loop_count": state.get("search_loop_count", 0) + 1
    }

def get_reflection_prompt(user_request: str, products: List, queries: List) -> List:
    """ê²°ê³¼ í‰ê°€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸"""
    system_prompt = """ë‹¹ì‹ ì€ ì œí’ˆ ì¶”ì²œ ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ìš”ì²­ê³¼ í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ íŒë‹¨í•´ì£¼ì„¸ìš”:

1. í˜„ì¬ ê²°ê³¼ê°€ ì‚¬ìš©ì ìš”ì²­ì„ ì¶©ì¡±í•˜ëŠ”ê°€?
2. ì œí’ˆ ë‹¤ì–‘ì„±ì´ ì¶©ë¶„í•œê°€?
3. ê°€ê²©ëŒ€ë³„ ì˜µì…˜ì´ ì ì ˆí•œê°€?
4. ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œ ì˜ì—­ì´ ìˆëŠ”ê°€?

ì¶©ë¶„í•œ ê²½ìš°: is_sufficient = true
ë¶€ì¡±í•œ ê²½ìš°: is_sufficient = false, ì¶”ê°€ ê²€ìƒ‰ì–´ ì œì•ˆ

ì‘ë‹µ í˜•ì‹:
- is_sufficient: true/false
- additional_queries: ì¶”ê°€ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸ (ë¶€ì¡±í•œ ê²½ìš°ë§Œ)
- gap_analysis: ë¶€ì¡±í•œ ë¶€ë¶„ ì„¤ëª…"""

    products_summary = "\n".join([f"- {p.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')}: {p.get('price_range', 'ê°€ê²© ë¯¸ìƒ')}" for p in products[:5]])
    
    return [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì‚¬ìš©ì ìš”ì²­: {user_request}\n\nê¸°ì¡´ ê²€ìƒ‰ì–´: {queries}\n\ní˜„ì¬ ì œí’ˆ ëª©ë¡:\n{products_summary}")
    ]

def should_continue_search(state: ProductRecommendationState) -> str:
    """ì¶”ê°€ ê²€ìƒ‰ í•„ìš”ì„±ì— ë”°ë¥¸ ë¼ìš°íŒ… ê²°ì •"""
    max_loops = state.get("max_search_loops", 2)
    current_loop = state.get("search_loop_count", 0)
    
    if state.get("is_sufficient", False) or current_loop >= max_loops:
        return "format_response"
    else:
        return "generate_search_queries"

def format_response(state: ProductRecommendationState, config: RunnableConfig) -> dict:
    """ìµœì¢… ì¶”ì²œ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    
    user_message = get_latest_user_message(state["messages"])
    candidate_products = state.get("candidate_products", [])
    
    if not candidate_products:
        response = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ì œí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì‹œê² ì–´ìš”?"
    else:
        response = format_product_recommendations(user_message, candidate_products)
    
    return {
        "response_to_user": response,
        "messages": [AIMessage(content=response)]
    }

def format_product_recommendations(user_request: str, products: List[Product]) -> str:
    """ì œí’ˆ ì¶”ì²œ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""
    
    response = f"**'{user_request}'** ìš”ì²­ì— ëŒ€í•œ ì¶”ì²œ ì œí’ˆì…ë‹ˆë‹¤! ğŸ¯\n\n"
    
    for i, product in enumerate(products[:5], 1):  # ìµœëŒ€ 5ê°œê¹Œì§€
        response += f"## {i}. {product['name']}\n\n"
        
        if product.get('price_range'):
            response += f"ğŸ’° **ê°€ê²©ëŒ€**: {product['price_range']}\n\n"
        
        if product.get('review_summary'):
            response += f"ğŸ“ **ì œí’ˆ ì •ë³´**:\n{product['review_summary']}\n\n"
        
        if product.get('purchase_link'):
            response += f"ğŸ›’ [êµ¬ë§¤í•˜ëŸ¬ ê°€ê¸°]({product['purchase_link']})\n\n"
        
        if product.get('source_url'):
            response += f"ğŸ“š [ìƒì„¸ ì •ë³´ ë³´ê¸°]({product['source_url']})\n\n"
        
        response += "---\n\n"
    
    response += "ğŸ’¡ **ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!**"
    
    return response

def should_refine_or_search(state: ProductRecommendationState) -> str:
    """ìš”ì²­ì˜ êµ¬ì²´ì„±ì— ë”°ë¥¸ ë¼ìš°íŒ… ê²°ì •"""
    return "search" if state.get("is_request_specific", False) else "refine"

# ========== ê·¸ë˜í”„ êµ¬ì„± ==========

def create_product_recommendation_graph():
    """ì œí’ˆ ì¶”ì²œ ê·¸ë˜í”„ ìƒì„±"""
    
    # ê·¸ë˜í”„ ë¹Œë” ì´ˆê¸°í™”
    builder = StateGraph(ProductRecommendationState, config_schema=ProductRecommendationConfig)
    
    # ë…¸ë“œ ì¶”ê°€
    builder.add_node("validate_request", validate_request)
    builder.add_node("generate_search_queries", generate_search_queries)
    builder.add_node("web_search", web_search)
    builder.add_node("reflection", reflection)
    builder.add_node("format_response", format_response)
    
    # ì—£ì§€ êµ¬ì„±
    builder.add_edge(START, "validate_request")
    builder.add_conditional_edges(
        "validate_request",
        should_refine_or_search,
        {
            "refine": END,  # êµ¬ì²´í™” ì§ˆë¬¸ìœ¼ë¡œ ì¢…ë£Œ
            "search": "generate_search_queries"  # ê²€ìƒ‰ ì§„í–‰
        }
    )
    builder.add_conditional_edges("generate_search_queries", continue_to_web_search, ["web_search"])
    builder.add_edge("web_search", "reflection")
    builder.add_conditional_edges(
        "reflection",
        should_continue_search,
        {
            "generate_search_queries": "generate_search_queries",  # ì¶”ê°€ ê²€ìƒ‰ í•„ìš”
            "format_response": "format_response"  # ê²€ìƒ‰ ì™„ë£Œ
        }
    )
    builder.add_edge("format_response", END)
    
    return builder.compile()

# ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (quickstart ë°©ì‹)
graph = create_product_recommendation_graph()
